{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7975,  1.2527, -1.5467, -2.2602, -0.2776],\n",
      "        [ 1.7801, -1.1552,  1.0755,  0.1323, -0.7811],\n",
      "        [ 0.6369, -0.0753, -0.0263, -0.0788,  1.5758],\n",
      "        [-0.1304,  0.0180, -0.2096,  0.4282,  0.0706]])\n",
      "tensor([[-0.3462,  1.1084,  0.1829,  1.1984, -0.0422],\n",
      "        [ 1.5083,  0.7871,  2.1530,  0.2748, -0.3317],\n",
      "        [-0.2050, -0.4623,  0.1864, -0.1468, -1.5075],\n",
      "        [ 0.8196, -0.9028, -0.0060,  0.1228, -0.6705]])\n",
      "tensor([[-0.9807, -0.6556, -1.0258,  0.7146, -2.3347],\n",
      "        [-1.1497,  0.5412, -1.1605, -0.6627, -0.2414],\n",
      "        [-0.0277, -0.5762,  0.1039,  0.6253,  0.5439],\n",
      "        [ 1.9239,  0.9743,  0.2935, -1.4634, -0.0098]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 5)\n",
    "y = torch.randn(4, 5)\n",
    "z = torch.randn(4, 5)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7801)\n"
     ]
    }
   ],
   "source": [
    "# max of the entire tensor\n",
    "m = torch.max(x)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max along a dimension \n",
    "\n",
    "torch.max(input, dim, keepdim=False, *, out=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7975,  1.2527, -1.5467, -2.2602, -0.2776],\n",
      "        [ 1.7801, -1.1552,  1.0755,  0.1323, -0.7811],\n",
      "        [ 0.6369, -0.0753, -0.0263, -0.0788,  1.5758],\n",
      "        [-0.1304,  0.0180, -0.2096,  0.4282,  0.0706]])\n",
      "tensor([1.7801, 1.2527, 1.0755, 0.4282, 1.5758])\n",
      "tensor([1, 0, 1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "m, idx = torch.max(x, 0)\n",
    "print(x)\n",
    "print(m)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7801, 1.2527, 1.0755, 0.4282, 1.5758])\n",
      "tensor([1, 0, 1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# 2 - 2\n",
    "m, idx = torch.max(input=x, dim=0)\n",
    "print(m)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7801, 1.2527, 1.0755, 0.4282, 1.5758])\n",
      "tensor([1, 0, 1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# 2 - 3\n",
    "m, idx = torch.max(x, 0, False)\n",
    "print(m)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.7801, 1.2527, 1.0755, 0.4282, 1.5758]])\n",
      "tensor([[1, 0, 1, 3, 2]])\n"
     ]
    }
   ],
   "source": [
    "# 2 - 4\n",
    "m, idx = torch.max(x, dim=0, keepdim=True)\n",
    "print(m)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7801, 1.2527, 1.0755, 0.4282, 1.5758])\n",
      "tensor([1, 0, 1, 3, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2660/3302760378.py:3: UserWarning: An output with one or more elements was resized since it had shape [1, 5], which does not match the required output shape [5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.max(x, 0, False, out=p)\n"
     ]
    }
   ],
   "source": [
    "# 2 - 5\n",
    "p = (m, idx)\n",
    "torch.max(x, 0, False, out=p)\n",
    "\n",
    "print(p[0])\n",
    "print(p[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put onto different device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Linear(5, 1).to(\"cuda:0\")\n",
    "\n",
    "x = torch.randn(5).to(\"cuda:0\")\n",
    "y = model(x)\n",
    "\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match the dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 5)\n",
    "y = torch.randn(5, 4)\n",
    "\n",
    "y = y.transpose(0, 1)\n",
    "z = z + y \n",
    "\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 0.])\n",
      "tensor([[0.1540, 0.9315, 0.3712, 0.2581, 0.7232],\n",
      "        [0.0072, 0.9839, 0.8478, 0.6936, 0.3783],\n",
      "        [0.3215, 0.4817, 0.2624, 0.2851, 0.7816],\n",
      "        [0.5404, 0.9774, 0.8896, 0.6105, 0.7310],\n",
      "        [0.7041, 0.0416, 0.5771, 0.3425, 0.0821]])\n",
      "tensor([1, 2, 3, 4, 0])\n",
      "tensor(1.4625)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "L = nn.CrossEntropyLoss()\n",
    "outs = torch.rand(5, 5)\n",
    "labels = torch.Tensor([1, 2, 3, 4, 0])\n",
    "print(labels)\n",
    "\n",
    "labels = labels.long()\n",
    "lossval = L(outs, labels)\n",
    "\n",
    "print(outs)\n",
    "print(labels)\n",
    "print(lossval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loader\n",
    "\n",
    "When using the dataloader, we often like to shuffle the data. This is where torch.utils.data.DataLoader comes in handy. If each data is an index (0, 1, 2...) from the view of torch.utils.data.DataLoader, shuffling can simply can be done by shuffling an index array.\n",
    "\n",
    "torch.utils.data.DataLoader will need two information to fulfill its role. First, it needs to know the length of the data. Second, once torch.utils.data.DataLoader outputs the index of the shuffling results, the datasets needs to return the corresponding data.\n",
    "\n",
    "Therefore, torch.utils.data.Dataset provides the information by two functions. `__len__()` and `__getitem__()` to support torch.utils.data.Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"abcdefghijklmnopqrstuvwxyz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n",
      "d\n",
      "e\n",
      "f\n",
      "g\n",
      "h\n",
      "i\n",
      "j\n",
      "k\n",
      "l\n",
      "m\n",
      "n\n",
      "o\n",
      "p\n",
      "q\n",
      "r\n",
      "s\n",
      "t\n",
      "u\n",
      "v\n",
      "w\n",
      "x\n",
      "y\n",
      "z\n"
     ]
    }
   ],
   "source": [
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t']\n",
      "['k']\n",
      "['r']\n",
      "['q']\n",
      "['d']\n",
      "['m']\n",
      "['x']\n",
      "['j']\n",
      "['a']\n",
      "['u']\n",
      "['f']\n",
      "['y']\n",
      "['o']\n",
      "['s']\n",
      "['h']\n",
      "['c']\n",
      "['g']\n",
      "['w']\n",
      "['e']\n",
      "['z']\n",
      "['p']\n",
      "['b']\n",
      "['v']\n",
      "['n']\n",
      "['i']\n",
      "['l']\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.utils.data \n",
    "\n",
    "class ExampleDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.data = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "\n",
    "    def __getitem__(self, idx): # if the index is idx, what will be data\n",
    "        return self.data[idx]\n",
    "\n",
    "    def __len__(self): # what is the length of the dataset\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "dataset = ExampleDataset() # create the dataset\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset = dataset,\n",
    "    shuffle = True, \n",
    "    batch_size = 1\n",
    ")\n",
    "\n",
    "for data in dataloader:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample data augmentation \n",
    "\n",
    "A simple data augmentation technique can be done by changing the code in `__len()__` and `__getitem__()`. Suppose we want to double the length of the dataset by adding in the uppercase letters, using only the lowercase dataset, you can change the dataset to the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
